# ç®€åŒ–ç‰ˆ NodeEncoder è®¾è®¡

## ğŸ¯ è®¾è®¡ç†å¿µ

**åˆ†å—ç¼–ç  (Multi-View Encoding)**: æ¯ç±»ç‰¹å¾å•ç‹¬ç¼–ç ï¼Œæœ€å concatã€‚

- âœ… **ä¸“é—¨åŒ–**: æ¯ç§ç‰¹å¾ç”¨æœ€é€‚åˆçš„ç¼–ç æ–¹å¼
- âœ… **ç®€æ´**: ä»£ç æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤  
- âœ… **é«˜æ•ˆ**: é¿å…å¤æ‚çš„ç‰¹å¾äº¤äº’è®¡ç®—
- âœ… **å¯æ‰©å±•**: å®¹æ˜“æ·»åŠ æ–°çš„ç‰¹å¾å—

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### è¾“å…¥
```python
PlanNode:
  â”œâ”€â”€ node_type: "Hash Join"
  â””â”€â”€ extra_info: {ç»Ÿè®¡ä¿¡æ¯, è°“è¯ä¿¡æ¯, ...}
```

### åˆ†å—ç¼–ç 
```python
1. ğŸ¯ ç®—å­ç±»å‹ â†’ Embedding Layer â†’ [32ç»´]
2. ğŸ“ˆ æ•°æ®ç»Ÿè®¡ â†’ MLP (logæ ‡å‡†åŒ–+å…¨è¿æ¥) â†’ [16ç»´]  
3. ğŸ” è°“è¯ä¿¡æ¯ â†’ Simple Encoder (å¤æ‚åº¦ç‰¹å¾) â†’ [8ç»´]
```

### ç‰¹å¾èåˆ
```python
Concat([32, 16, 8]) â†’ Linear Projection â†’ [64ç»´]
```

## ğŸ“ æ ¸å¿ƒå®ç°

### 1. ç®—å­ç±»å‹ç¼–ç 
```python
def _encode_operator(self, node) -> torch.Tensor:
    # åŠ¨æ€æ‰©å±•è¯æ±‡è¡¨ + Embeddingå±‚
    node_type = getattr(node, "node_type", "Unknown")
    idx = self.node_type_vocab[node_type] 
    return self.operator_embedding(torch.tensor([idx])).squeeze(0)
```

### 2. æ•°æ®ç»Ÿè®¡ç¼–ç   
```python
def _encode_stats(self, node) -> torch.Tensor:
    # æå–: Plan Rows, Plan Width, Startup Cost, Total Cost
    # å¤„ç†: log1pæ ‡å‡†åŒ– â†’ MLP
    stats_tensor = torch.log1p(torch.tensor(stats_values))
    return self.stats_mlp(stats_tensor)
```

### 3. è°“è¯ä¿¡æ¯ç¼–ç 
```python
def _encode_predicate(self, node) -> torch.Tensor:
    # å¤æ‚åº¦ç‰¹å¾: è°“è¯æ•°é‡ã€èŒƒå›´è¿‡æ»¤ã€å­æŸ¥è¯¢ã€å‡½æ•°è°ƒç”¨ç­‰
    # è¿”å›å›ºå®šç»´åº¦çš„ç‰¹å¾å‘é‡
    return torch.tensor(complexity_features)
```

## ğŸš€ ä½¿ç”¨æ–¹å¼

### åŸºæœ¬ä½¿ç”¨
```python
# åˆ›å»ºç¼–ç å™¨
encoder = create_node_encoder(
    operator_dim=32,
    stats_dim=16, 
    predicate_dim=8,
    output_dim=64
)

# ç¼–ç èŠ‚ç‚¹
vector = encoder.encode_node(node)  # torch.Tensor [64]
```

### å·¥å‚å‡½æ•°
```python
# ç®€å•ç‰ˆ (å°ç»´åº¦)
encoder = create_simple_node_encoder()  # è¾“å‡º32ç»´

# æ ‡å‡†ç‰ˆ
encoder = create_node_encoder()         # è¾“å‡º64ç»´

# å¤§å®¹é‡ç‰ˆ (å¤§ç»´åº¦)  
encoder = create_large_node_encoder()   # è¾“å‡º128ç»´
```

## ğŸ’¡ å…³é”®ç‰¹æ€§

### 1. åŠ¨æ€è¯æ±‡è¡¨æ‰©å±•
- è‡ªåŠ¨å¤„ç†æ–°çš„ç®—å­ç±»å‹
- Embeddingå±‚åŠ¨æ€æ‰©å±•ï¼Œä¿æŒå·²å­¦ä¹ æƒé‡

### 2. ç®€æ´çš„ç‰¹å¾å¤„ç†
- ç»Ÿè®¡ç‰¹å¾: logæ ‡å‡†åŒ– + MLP
- è°“è¯ç‰¹å¾: 6ä¸ªå¤æ‚åº¦æŒ‡æ ‡
- æ— å†—ä½™ç¼–ç æ–¹æ³•

### 3. PyTorchåŸç”Ÿæ”¯æŒ
- ç»§æ‰¿è‡ª `nn.Module`
- æ”¯æŒæ¢¯åº¦ä¼ æ’­å’Œè®­ç»ƒ
- è¿”å› `torch.Tensor`

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç‰¹æ€§ | ç®€åŒ–ç‰ˆ | åŸå¤æ‚ç‰ˆ |
|------|--------|----------|
| ä»£ç è¡Œæ•° | ~280è¡Œ | ~1150è¡Œ |
| ç¼–ç æ–¹æ³•æ•° | 3ä¸ªæ ¸å¿ƒæ–¹æ³• | 15+ä¸ªæ–¹æ³• |
| å·¥å‚å‡½æ•° | 3ä¸ª | 8ä¸ª |
| ç»´æŠ¤å¤æ‚åº¦ | ä½ | é«˜ |
| åŠŸèƒ½å®Œæ•´æ€§ | âœ… æ ¸å¿ƒåŠŸèƒ½å®Œæ•´ | âŒ åŠŸèƒ½é‡å¤å†—ä½™ |

## ğŸ”§ æ‰©å±•æŒ‡å—

å¦‚éœ€æ·»åŠ æ–°ç‰¹å¾å—:

```python
def _encode_new_feature(self, node) -> torch.Tensor:
    # å®ç°æ–°ç‰¹å¾çš„ç¼–ç é€»è¾‘
    return feature_vector

def forward(self, node) -> torch.Tensor:
    # åœ¨concatä¸­æ·»åŠ æ–°ç‰¹å¾
    new_vec = self._encode_new_feature(node)
    combined = torch.cat([operator_vec, stats_vec, predicate_vec, new_vec])
    return self.output_projection(combined)
```

## âœ… æ€»ç»“

ç®€åŒ–ç‰ˆ NodeEncoder å®ç°äº†**åˆ†å—ç¼–ç **çš„æ ¸å¿ƒæ€æƒ³:
- ğŸ¯ **ç®—å­embedding** + ğŸ“ˆ **ç»Ÿè®¡MLP** + ğŸ” **è°“è¯encoder** + ğŸ”— **concat**
- ä»£ç ç®€æ´ï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- å®Œå…¨ç¬¦åˆä½ çš„éœ€æ±‚: "åªä¿ç•™åˆ†å—ç¼–ç ï¼Œæ¯ç±»ç‰¹å¾å•ç‹¬ç¼–ç ï¼Œæœ€åconcat"
